---
title: "Lab Bayesian"
author: "Andres Navarro"
date: "2023-04-25"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
setwd("/home/me/MEGA/Uni/3YEAR/Q2/01\ Bayesian Analysis/Lab")

library(unix)
rlimit_as(1e12)  #increases to ~12GB
```

# Dataset Lookup

First of all, the objective of this Case Study will be to show the advantages of Bayesian Statistics for small data sets and the ability to estimated better the posterior parameters.. As it is known, Bayesian Statistics allows as to set up prior believes of our predictors with specific probability distributions. This is really useful when we do not have a lot of data and we have some insights on the data. For this reason I have decided to use a data set with 21 variables and I will be reducing the number of observations to simulate what we are trying to show. This data is about the COVID cases in Mexico and the goal is to predict if a patient has COVID or not.

[[<https://www.kaggle.com/datasets/meirnizri/covid19-dataset>][Dataset]]

```{r}
rm(list = ls())
data = read.csv("data.csv", header = TRUE)
dim(data)
```

```{r}
summary(data)
```

The raw data set consists of 21 unique features and 1,048,576 unique patients. In the Boolean features, 1 means "yes" and 2 means "no". values as 97 and 99 are missing data.

-   sex: 1 for female and 2 for male.
-   age: of the patient.
-   classification: covid test findings. Values 1-3 mean that the patient was diagnosed with covid in different
-   degrees. 4 or higher means that the patient is not a carrier of covid or that the test is inconclusive.
-   patient type: type of care the patient received in the unit. 1 for returned home and 2 for hospitalization.
-   pneumonia: whether the patient already have air sacs inflammation or not.
-   pregnancy: whether the patient is pregnant or not.
-   diabetes: whether the patient has diabetes or not.
-   copd: Indicates whether the patient has Chronic obstructive pulmonary disease or not.
-   asthma: whether the patient has asthma or not.
-   inmsupr: whether the patient is immunosuppressed or not.
-   hypertension: whether the patient has hypertension or not.
-   cardiovascular: whether the patient has heart or blood vessels related disease.
-   renal chronic: whether the patient has chronic renal disease or not.
-   other disease: whether the patient has other disease or not.
-   obesity: whether the patient is obese or not.
-   tobacco: whether the patient is a tobacco user.
-   usmr: Indicates whether the patient treated medical units of the first, second or third level.
-   medical unit: type of institution of the National Health System that provided the care.
-   intubed: whether the patient was connected to the ventilator.
-   icu: Indicates whether the patient had been admitted to an Intensive Care Unit.
-   date died: If the patient died indicate the date of death, and 9999-99-99 otherwise.

Here we can see a summary of the data, first we have to clean and adapt the data so we can work on it. First of all, I will create the variable that we want to predict that is if a patient has been diagnosed with COVID or not.

```{r}
data$COVID = ifelse(data$CLASIFFICATION_FINAL <= 3, 1, 2)
data = subset(data, select = -c(CLASIFFICATION_FINAL))
```

```{r}
convertToLogic = function(col.name, df) {
  index = which(names(df) == col.name)
  print(index)

  if (length(index) != 0) {
    df[, index] = ifelse(df[, index] == 2, 0, df[, index])
    df[, index] = as.logical(df[, index])
    
  }
  
  return(df)
}
```

This column will tell us if a patient has been diagnosed with COVID or not. Then, I will factor and format all the other variables to adapt them properly.

```{r}
data = convertToLogic("COVID", data)

data$USMER = ifelse(data$USMER == 2, 0, data$USMER)
data$USMER = as.logical(data$USMER)

data$MEDICAL_UNIT = factor(data$MEDICAL_UNIT)

data$SEX = factor(data$SEX, labels = c("female", "male"), levels = c(1, 2))

data$PATIENT_TYPE = factor(data$PATIENT_TYPE, labels = c("returned home", "hospitalized"), levels = c(1, 2))

data$INTUBED = factor(data$INTUBED, labels = c("intubed", "not intubed"), levels = c(1, 2))

data$PNEUMONIA = factor(data$PNEUMONIA, labels = c("pneumonia", "not pneumonia"), levels = c(1, 2))

data$PREGNANT = factor(data$PREGNANT, labels = c("pregnant", "not pregnant"), levels = c(1, 2))

data$DIABETES = factor(data$DIABETES, labels = c("diabetes", "not diabetes"), levels = c(1, 2))

data$COPD = factor(data$COPD, labels = c("copd", "not copd"), levels = c(1, 2))

data$ASTHMA = factor(data$ASTHMA, labels = c("asthma", "not asthma"), levels = c(1, 2))

data$INMSUPR = factor(data$INMSUPR, labels = c("inmsupr", "not inmsupr"), levels = c(1, 2))

data$HIPERTENSION = factor(data$HIPERTENSION, labels = c("hipertension", "not hipertension"), levels = c(1, 2))

data$OTHER_DISEASE = factor(data$OTHER_DISEASE, labels = c("other desease", "not other desease"), levels = c(1, 2))

data$CARDIOVASCULAR = factor(data$CARDIOVASCULAR, labels = c("cardiovascular", "not cardiovascular"), levels = c(1, 2))

data$OBESITY = factor(data$OBESITY, labels = c("obesity", "not obesity"), levels = c(1, 2))

data$RENAL_CHRONIC = factor(data$RENAL_CHRONIC, labels = c("renal chronic", "not renal chronic"), levels = c(1, 2))

data$TOBACCO = factor(data$TOBACCO, labels = c("tobacco", "not tobacco"), levels = c(1, 2))

data$ICU = factor(data$ICU, labels = c("icu", "not icu"), levels = c(1, 2))

data = subset(data, select = -c(DATE_DIED))

```

```{r}
summary(data)
```

Here we see that the data is correctly formated but there are some missing value, so let's fix that.

## Data Cleaning

First we will see how manu missing values there are by rows so we can remove some columns that have a lot of missing values.

```{r}
print(length(which(is.na(data))))

hist(rowMeans(is.na(data)), xlab = c("Missing values average by rows"), main = c())
```

Here we see that there are 3 columns with the most missing values.

```{r}
indexesEmptyCols = which(colMeans(is.na(data)) != 0)

colsWithNA = sort(colMeans(is.na(data[, indexesEmptyCols])), 
                  decreasing = TRUE)

barplot(colsWithNA, las=2)
```

And the columns that have the most missing values are ICU, INTUBED, and PREGNANT, so let's remove them.

```{r}
data = subset(data, select = -c(ICU, INTUBED, PREGNANT))

print(length(which(is.na(data))))
```

```{r}
data = na.omit(data)

length(unique(which(is.na(data))))
```

```{r}
summary(data)
```

Now the data set is clean so let's start working on it. But first we will shrink it to 1000 observations to work with.

```{r}
data.small = data[sample(nrow(data), size=1000),]
```


# Bayesian Analysis of the covid variable

First of all, let's plot a histogram of the COVID variable (the one we want to predict) and see.

```{r}
rm(list = setdiff(ls(), c("data", "data.small")))

hist(as.numeric(data$COVID))
```

This is as we expected as we are going to be predicting a binary variable. So let's use a Bernoulli distribution to explain this data and see how well it fits. First of all lets compute the analytical posterior distribution of the covid variable.

## Analytical Study

1.  We assume a Bernoulli distribution for COVID, we will use X to denote that variable.

$$X \ | \ \theta \thicksim Bernoulli(\theta)$$
$$f(x \ | \ \theta) = \theta^x \cdot (1 - \theta)^x$$

2. As we do not have any prior knowledge on the probability of a patient of having covid, we will define the prior distribution as an improper prior. Moreover, we will be using a Beta distribution as in the end we will get a posterior conjugate which will be much easier to work with.

$$\theta \thicksim Beta(0, 0)$$
$$f(\theta \ | \ 0, 0) = \frac{\theta^{0 - 1} \cdot (1 - \theta)^{0 - 1}}{B(0, 0)} $$
3. Now we get the likelihood

$$f(data \ | \ \theta) \propto \theta^{k} \cdot (1 - \theta)^{n - k}$$

Being n the total number of observations and k the positive ones.

4. And finally the posterior distribution

$$f(\theta \ | \ data) = \frac{\theta^{k - 1} \cdot (1 - \theta)^{n - k - 1}}{B(k, n - k)} $$

$$\theta \ | \ data \thicksim Beta(k, n - k)$$

So now that we have the posterior distribution let's obtain the prediction of the next value called Y given the data

$$Y \ | \ \theta \thicksim Bernuilli(\theta)$$
$$P ( Y = 1 | data) = \int_{-\infty}^{\infty}{P(Y=1|\theta) \cdot P(\theta | data) d\theta} \\
= \frac{B(k + 1, n - k)}{B(k, n - k)}$$

```{r}
n = as.numeric(length(data.small$COVID))
k = as.numeric(length(which(data.small$COVID)))
print(beta(k+1,n-k)/beta(k, n-k))
```

And here we can see that the probability of a new patient of having covid is 0.362 that is really close to the ML estimator of 0.38

And finally let's try to obtain the same result numerically

## Numerical Study

As we know the distribution of the new observation we will get a random sample and compare.

$$Y \ | \ \theta \thicksim  Bernuilli ( Beta (k, n - k))$$

```{r}
y.sample = rbinom(n, 1, rbeta(1, k, n - k))

mean(y.sample)
```

Here we see that the estimated probability is almost the same as previously. 

```{r}
covid.prob = rbeta(n, k, n - k)
quantile(covid.prob, probs = c(0.025, 0.975))
```

And also we see that the confidence interval for the probability of having covid is pretty narrow, so we can be sure that it is correct.

# Data Exploration

Now, we will see if the other variables are useful to predict if a patient has covid or not.

```{r}
rm(list = setdiff(ls(), c("data", "data.small")))

library(ggplot2) # GGally
library(GGally)

ggcorr(data, cor_matrix = cor(sapply(data, as.numeric)), label = TRUE)
```

Here we see that there is some correlation between the columns but nothing strong with respect to the COVID variable so lets see if we can identify better which columns have more correlation with the covid column.

```{r}
corr_covid = sort(cor(sapply(subset(data, select = -c(COVID)), as.numeric))[1,], decreasing = T)

corr = data.frame(corr_covid)

ggplot(corr,aes(x = row.names(corr), y = corr_covid)) + geom_bar(stat = "identity") + 
  scale_x_discrete(limits= row.names(corr)) +  labs(x = "", y = "covid", title = "Correlations") + 
  theme(plot.title = element_text(hjust = 0, size = rel(1.5)), axis.text.x = element_text(angle = 45, hjust = 1))
```

Here we see that USMER has the most correlation and this makes sense as it indicated if the pacient has received medication.

Now let's see how the columns distribute with respect to the covid variable.

```{r}
ggplot(data, aes(x=COVID, y=AGE)) + 
  geom_boxplot()
```

Here we see that there is a visible difference between the mean of the covid, so this can be a useful variable to use in our model.

```{r}
plot(table(data$COVID, data$USMER))
plot(table(data$COVID, data$MEDICAL_UNIT))
plot(table(data$COVID, data$SEX))
plot(table(data$COVID, data$PATIENT_TYPE))
plot(table(data$COVID, data$PNEUMONIA))
plot(table(data$COVID, data$DIABETES))
plot(table(data$COVID, data$COPD))
plot(table(data$COVID, data$ASTHMA))
plot(table(data$COVID, data$INMSUPR))
plot(table(data$COVID, data$HIPERTENSION))
plot(table(data$COVID, data$OTHER_DISEASE))
plot(table(data$COVID, data$CARDIOVASCULAR))
plot(table(data$COVID, data$OBESITY))
plot(table(data$COVID, data$RENAL_CHRONIC))
plot(table(data$COVID, data$TOBACCO))
```

Now, the columns that show off the most are: MEDICAL_UNIT, SEX, PATITENT_TYPE, and PNEUMONIA. This makes sense and we will see after if we are confident that there is a visible difference.

# Frequentist LM

Now let's implement a simple LM model to see how well we can predict a patient to have covid.

```{r}
rm(list = setdiff(ls(), c("data")))

library(caret)
library(lattice)

data.small = data[sample(nrow(data), size=10000),]

index.test = createDataPartition(data.small$COVID, p = 0.5, list = FALSE)

data.test = data.small[index.test,]
data.train = data.small[-index.test,]

rm(index.test)
```

Now first of all let's try to use all the variables to try to predict if a patient has covid or not.

```{r}
fit = train(as.factor(COVID) ~ ., data = data.train, method = "glm", family = "binomial")

summary(fit)
```
Here we see that there are a lot of variables that are useless. As the p value of the betas is really high for most of them.

```{r}
confusionMatrix(as.factor(data.test$COVID), predict(fit, newdata = data.test))
```

Here, we see that we get an accuracy of 0.6578 so it is not that bad, probably it is because we only have a few significant variables as we saw in the correlation graph. So let's try a simpler model.

```{r}
fit = train(as.factor(COVID) ~ USMER + PNEUMONIA + MEDICAL_UNIT + DIABETES + HIPERTENSION + AGE + PATIENT_TYPE, data = data.train, method = "glm", family = "binomial")

summary(fit)
```
Now it is better but the medical unit for example, it is only relevant the level 2 and also for other.

```{r}
confusionMatrix(as.factor(data.test$COVID), predict(fit, newdata = data.test))
```
Here we see that the accuracy is almost the same and the kappa so we have not lost a lot of info.

# Bayesian LM

The frequentest approach is easier but we if we want to compute confidence intervals for the parameters or predictive intervals we cannot do them. That is why we will be using the Bayesian approach to better study the effects of each variable with covid and get more conclusions. The power of the Bayesian approach is that we obtain the posterior distribution of the parameters so we can study better the relation and the significance. So let's start.

```{r message=FALSE}
library(coda)
library(MASS)
library(MCMCpack)
```

```{r}
rm(list = setdiff(ls(), c("data", "data.small", "data.test", "data.train")))

fit = MCMClogit(COVID ~ ., data = data.train, burnin=1000, mcmc=210000)
```

```{r}
par(mar=c(1, 1, 1, 1))
plot(fit)
```

```{r}
summary(fit)
```


## Lasso

```{r}
rm(list = setdiff(ls(), c("data", "data.small", "data.test", "data.train")))

library(monomvn)

x = data.frame(data.train$USMER, as.numeric(data.train$MEDICAL_UNIT))
y = data.train$COVID
fit = blasso(x, y)

plot(fit, burnin=200)
```

```{r}
rm(list = setdiff(ls(), c("data", "data.small", "data.test", "data.train")))

library(R2OpenBUGS)

model = function() {
  
}
```


# Bayesian LM with Lasso / Ridge
